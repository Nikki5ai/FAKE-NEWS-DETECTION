{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nikki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nikki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nikki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 56.15%\n",
      "âœ… REAL News ðŸ“°\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import metrics\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "file_path = r'C:\\Users\\Nikki\\OneDrive\\Desktop\\Pictures\\Documents\\BTECH\\SLASHMARK\\BASIC PROJECTS\\Fake_News_Detection-master\\train.csv'\n",
    "train_df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns exist\n",
    "if 'Statement' not in train_df.columns or 'Label' not in train_df.columns:\n",
    "    raise ValueError(\"Dataset must contain 'Statement' and 'Label' columns.\")\n",
    "\n",
    "# Drop missing values\n",
    "train_df.dropna(subset=['Statement', 'Label'], inplace=True)\n",
    "\n",
    "# Convert categorical labels ('FAKE'/'REAL') to binary (0/1) if necessary\n",
    "if train_df['Label'].dtype == 'object':\n",
    "    train_df['Label'] = train_df['Label'].map({'FAKE': 0, 'REAL': 1})\n",
    "\n",
    "# Text preprocessing function\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stpwrds = set(stopwords.words('english'))\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    words = wordpunct_tokenize(text)  # Alternative tokenizer\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stpwrds]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "# train_df['Statement'] = train_df['Statement'].astype(str).apply(clean_text)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_df['Statement'], train_df['Label'], test_size=0.3, random_state=1)\n",
    "\n",
    "# Convert text to TF-IDF vectors\n",
    "tfidf_v = TfidfVectorizer()\n",
    "tfidf_X_train = tfidf_v.fit_transform(X_train)\n",
    "tfidf_X_test = tfidf_v.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "classifier = PassiveAggressiveClassifier()\n",
    "classifier.fit(tfidf_X_train, Y_train)\n",
    "\n",
    "# Evaluate model\n",
    "Y_pred = classifier.predict(tfidf_X_test)\n",
    "accuracy = round(metrics.accuracy_score(Y_test, Y_pred) * 100, 2)\n",
    "print(f'Model Accuracy: {accuracy}%')\n",
    "\n",
    "# Save model and vectorizer\n",
    "pickle.dump(classifier, open('./model.pkl', 'wb'))\n",
    "pickle.dump(tfidf_v, open('./vectorizer.pkl', 'wb'))\n",
    "\n",
    "# Load model and vectorizer\n",
    "loaded_model = pickle.load(open('./model.pkl', 'rb'))\n",
    "loaded_vectorizer = pickle.load(open('./vectorizer.pkl', 'rb'))\n",
    "\n",
    "# Function to detect fake news\n",
    "def fake_news_det(news):\n",
    "    processed_news = clean_text(news)\n",
    "    vectorized_input = loaded_vectorizer.transform([processed_news])\n",
    "    prediction = loaded_model.predict(vectorized_input)\n",
    "    print(\"ðŸ›‘ FAKE News ðŸ“°\" if prediction[0] == 0 else \"âœ… REAL News ðŸ“°\")\n",
    "\n",
    "# Example usage\n",
    "fake_news_det(\"Breaking news! The president just announced a major policy change.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
